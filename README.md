
# Troubleshooting and Debugging Techniques

## Troubleshooting Concepts

### Debugging

* Tools that can be helpful:

    * Tools like **tcpdump** and **Wireshark** can show us ongoing network connections, and help us analyze the traffic going over our cables.

    * Tools like **ps**, **top**, or **free** can show us the number and types of resources used in the system.

    * We can use a tool like **strace** to look at the system calls made by a program, or **ltrace** to look at the library calls made by the software.

* Helpful pieces of advice and Terms:

    * **Troubleshooting** is the process of identifying, analyzing, and solving problems.

    * **Debugging** is the process of identifying, analyzing, and removing bugs in a system.

    * **Debuggers** let us follow the code line by line, inspect changes in variable assignments, interrupt the program when a specific condition is met, and more.

### Problem Solving Steps

* The problem solving steps are:

    1. Getting information
    1. Finding the root cause
    1. Performing the necessary remediation

* Helpful pieces of advice and Terms:

    * **Reproduction case** is a clear description of how and when the problem appears.

    * **Immediate remediation** gets the system back to health.

    * **Medium** or **long-term remediation** avoids the problem in the future.

### Silently Crashing Application

* **Commands**:
    * __strace ./program__ - traces a system calls made by the program and tell us what the result of each of these calls was.
    * __strace -o new_file ./program__ - creates a new file with the results of system calls made by the program.
    * __strace ./script.py | less__ - piping the less command allows you to scroll through a lot of text output. 

* Helpful pieces of advice and Terms:

    * **System calls** are the calls that the programs running on our computer make to the running kernel.

### "It Doesn't Work"

* **Common questions**:
    * What were you trying to do? 
    * What steps did you follow? 
    * What was the expected result? 
    * What was the actual result?

* Helpful pieces of advice and Terms:

    * **The load average** on Linux shows how much time a processor is busy in a given minute, with one meaning it was busy for the whole minute. 

    * Normally this number(the load average) shouldn't be above the amount of processors in the computer.

    * A number(the load average) higher than the amount of processors means the computer is overloaded. 

### Creating a Reproduction Case

1. Read the logs available
    * Which logs to read, will depend on the operating system and the application that you're trying to debug.
1. Isolate the conditions that trigger the issue
    * Do other users in the same office also experienced the problem? 
    * Does the same thing happen if the same user logs into a different computer? 
    * Does the problem happen if the applications config directory is moved away?

* Helpful pieces of advice and Terms:

    * **Reproduction case** is a way to verify if the problem is present or not.

### Finding the Root Cause

* Finding the actual root cause of the problem includes the next steps:
    1. Looking at the information we have
    1. Coming up with a hypothesis that could explain the problem
    1. Testing our hypothesis
    1. Go back to the beginning and try different possibility

* Tools that can be helpful:

    * **iotop** is a tool similar to top that lets us see which processes are using the most input and output. 

    * Other related tools are **iostat** and **vmstat**, these tools show statistics on the input/output operations and the virtual memory operations.

    * If the issue is that the process generates too much input or output, we could use a command like **ionice** to make our backup system reduce its priority to access the disk and let the web services use it too.

    * **iftop** is another tool similar to top that shows the current traffic on the network interfaces.

    * The **rsync** command, whic
    h is often used for backing up data, includes a **-bwlimit** for checking if the backup software already includes an option to limit the bandwidth.

    * A program **Trickle** can be used to limit the bandwidth being used.

    * The **nice** command reduces the priority of the process and accessing the CPU.

* Helpful pieces of advice and Terms:

    * Understanding the root cause is essential for performing the **long-term remediation**.

    * Whenever possible, we should check our hypothesis in a test environment, instead of the production environment that our users are working with.

### Dealing with Intermittent Issues

* Rebooting a computer or restarting a program changes a bunch of things like:
    * Going back to a clean slate means releasing all allocated memory
    * Deleting temporary files
    * Resetting the running state of programs
    * Re-establishing network connections
    * Closing open files and more

* Depending on what the problem is, you might want to look at different sources of information, like:
    * The load on the computer
    * The processes running at the same time
    * The usage of the network, and so on

* Heisenbugs usually point to these factors:
    * Bad resource management
    * Wrongly allocated memory
    * Not correctly initialized network connections
    * Not properly handled open files

* Helpful pieces of advice and Terms:

    * If a problem goes away by turning it off and on again, there's almost certainly a bug in the software, and the bug probably has to do with not managing resources correctly.

    * Power cycling releases resources stored in cache or memory, which gets rid of the problem.

    * Sometimes, the bug goes away when we *add extra logging information*, or when we *follow the code step by step using a debugger*. This is an especially annoying type of intermittent issue, nicknamed **Heisenbug**, in honor of Werner Heisenberg. He's the scientist that first described the observer effect, where just observing a phenomenon alters the phenomenon.

    * **Observer effect** means that when just observing a phenomenon alters the phenomenon.

* Jokes:

    * There's plenty of jokes related to how, in IT, a lot of what we do to solve problems, is just turn things off and on again.

### Intermittently Failing Script

* Tools that can be helpful:
    * **Zenity** is the application showing the window to select the date, title, and emails.

* Helpful pieces of advice and Terms:
    * In general, when dates are involved in a failure, the problem is due to **how the dates are formatted**.

### What is binary search?

* **Linear search** example: 
    1. Start from the first entry 
    1. Check if the name is the one that we're looking for
    1. If it doesn't match, move to the second element 
    1. Check again
    1. Keep going until we find the employee with the name we're looking for, *or we get to the end of the list*

* **Binary search** example
(*because the list is sorted, we can make decisions about the position of the elements in the list*):

    1. Compare the name that we're looking for with the element in the middle of the list
    1. Check if it's equal, smaller, or bigger
    1. Eliminated half of the list
    1. Do the same thing again until we find the element

* Helpful pieces of advice and Terms:

    * Usually when trying to find the root cause of a problem, we'll be looking for one answer in a list of many.

### Applying Binary Search in Troubleshooting

* Commands:

    *  **git bisect** - finds the commit that broke the program/process and report this as a bug to be fixed.

* Helpful pieces of advice and Terms:

    * **Bisecting** means dividing in two.

    * **Bisect** receives two points in time in the Git history and repeatedly lets us try the code at the middle point between them until we find the commit that caused the breakage.

## Slowness

### Why is my computer slow?

* Diagnosing what's causing your computer to run slow:
    * open one of these tools.
    * check out what's going on.
    * understand which resources the bottleneck and why.
    * plan how you're going to solve the issue.

* The **bottleneck** could be:
    * CPU time 
    * time spent reading data from disk waiting for data transmitted over the network
    * moving data from disk to RAM
    * some other resource that's limiting the overall performance.

* If the problem is:

    * **your program needs more CPU time** - close other running programs that you don't need. 

    * **you don't have enough space on disk** - uninstall, delete or move applications or data you don't need. 

    * **the application needs more network bandwidth** - stop any other processes that are using the network.

    * **the hardware we're using just isn't good enough**  - upgrade the underlying hardware.

* Hardware that needs to be changed can be: 
    * the CPU
    * the memory
    * the disk IO
    * the network connection
    * the graphics card

* Tools that can be helpful:

    * **top** -  lets us see which currently running processes are using the most CPU time on Linux systems.

    * **iotop** and **iftop** help us see which processes are currently using the most disk IO usage or the most network bandwidth. 

    * **Activity Monitor** - lets us see what's using the most CPU, memory, energy, disk, or network on MacOS. 

    * **Resource Monitor** and **Performance Monitor** -  let us analyze what's going on with the different resources on the computer including CPU, memory, disk and network on Windows

* Helpful pieces of advice and Terms:

    * Each application gets a fraction of the CPU time, and then the next application gets a turn.

    * Strategy for addressing slowness is to **identify the bottleneck** for addressing slowness in our device, our script, or our system to run slowly.

    * To tell which piece of hardware needs to be changed we need to **monitor the usage of our resources** to know which of them as being exhausted.

    * Sometimes, we need to figure out what the **software** is doing wrong and where it's spending most of its time to understand how to make it run faster. 

### How Computers Use Resources

* The time spent retrieving data depends on where it's located:
    * CPU
    * Disk
    * Memory
    * Network

* Examples of caches in IT:
    * A web proxy, *stores websites, images, or videos that are accessed often by users behind the proxy*.  * DNS services, *implement a local cache for the websites they resolve*.
    * The operating system, *takes care of some caching for us*.
    * The contents of files or libraries that are accessed often, *even if they aren't in use right now* are **the contents are cached** in memory.

* After running out of RAM:
    * The OS will just remove from RAM anything that's cached, *but not strictly necessary*.
    * The operating system will put the parts of the memory that aren't currently in use onto the hard drive in a space called **swap**.

* The machine is slow because:
    * There are too many open applications
    * The available memory is just too small for the amount that computer is using
    * The running programs may have a memory leak, *causing it to take all the available memory*. 
    
* Helpful pieces of advice and Terms:   
    * A **memory leak** means that memory which is no longer needed is not getting released.
    * **Cache** stores data in a form that's faster to access than its original form.
    * **The swapping implementation's concept** is The information that's not needed right now is removed from RAM and put onto the disk, while the information that's needed now is put into RAM.
    * If a program is using a lot of memory and this stops when you restart the program, it's probably because of a **memory leak**.

### Possible Causes of Slowness

* Slowness:
    * Too many applications configured to start on boot.
    * A program that's keeping some state while running that's causing the computer to slow down.
    * Hardware failures
    * Malicious software

* Helpful pieces of advice and Terms: 

    * If it's slow when starting up, it's probably a sign that **there are too many applications configured to start on boot**.

    * If instead the computer becomes sluggish after days of running just fine, and the problem goes away with a reboot, it means that **there's a program that's keeping some state while running** that's causing the computer to slow down.

    * Solution: schedule a regular restart to mitigate both the slow program and your computer running out of RAM. Reduce the size of the files involved. If the file is a log file, you can use a program like **logrotate**.

    * If your hard drive has errors, the computer might still be able to apply error correction to get the data that it needs, but it will affect the overall performance.

### Slow Web Server

a tool called ab which stands for Apache Benchmark tool to figure out how slow it is. We'll run ab -n 500 to get the average timing of 500 requests, and then pass our site.example.com for the measurement.

the load average on Linux shows how much time the processor is busy at a given minute with one meaning it was busy for the whole minute.

The process priorities in Linux are so that the lower the number, the higher the priority

Typical numbers go from 0 to 19. 
But we can change that using the nice and renice commands

For that, we'll use the pidof command that receives the process name and returns all the process IDs that have that name.

Renice takes the new priority as the first argument, and the process ID to change as the second one. I

for pid in $(pidof ffmpeg); do renice 19 $pid; 

We'll call ps ax which shows us all the running processes on the computer, and we'll connect the output of the command to less, to be able to scroll through it. 
ps ax | less

the locate command to see if we can find them. We'll first exit the less interface with queue and then call locate static/001.webm.

a tool called Daemonize that runs each program separately as if it were a daemon

So we'll use the killall command with the -STOP flag which sends a stop signal but doesn't kill the processes completely

for pid in $(pidof ffmpeg); do while kill - CONT $pid; do sleep 1; done; done

### Writing Efficient Code

we should always start by writing clear code that does what it should and only try to make it faster if we realize that it's not fast enough.

trying to optimize every second out of a script is probably not worth your time.

If we want our code to finish faster, we need to make our computer do less work

to avoid doing work that isn't really needed. How? There's a bunch of different things to do. The most common ones include storing data that was already calculated to avoid calculating it again using the right data structures for the problem and reorganizing the code so that the computer can stay busy while waiting for information from slow sources like disk or over the network.

. A profiler is a tool that measures the resources that our code is using, giving us a better understanding of what's going on

In particular, they help us see how the memory is allocated and how the time spent

So we would use gprof to analyze a C program but use the c-Profile module to analyze a Python program. 

The cProfile module is used to count how many times functions are called, and how long they run.

### Using the Right Data Structures

if you need to access elements by position or will always iterate through all the elements, use a list to store them.

if we need to look up the elements using a key, we'll use a dictionary.

Another thing that we might want to think twice about is creating copies of the structures that we have in memory.

### Expensive Loops

If you do an expensive operation inside a loop, you multiply the time it takes to do the expensive operation by the amount of times you repeat the loop.

how you access the data inside the loop. If the data is stored in a file, your script will need to parse the file to fetch it. 

Whenever you have a loop in your code, make sure to check what actions you're doing, and see if there are operations you can take out of the loop to do them just once
Instead of making one network call for each element, make one call before the loop. Instead of reading from disk for each element, read the whole thing before the loop. 

Make sure that the list of elements that you're iterating through is only as long as you really need it to be. 

Instead, you could modify the service to store the user access info in log files that can be read if necessary and only keep the last five logins in memory

Another thing to remember about loops is to break out of the loop once you found what you were looking for.

### Keeping Local Results

if we have to parse a file, we do it once before we call the loop instead of doing it for each element of the loop. 

If the script gets executed fairly regularly, it's common to create a local cache.

We need to think about how often we're going to update the cache and what happens if the data in the cache is out of date.

you'll want to look for strategies that let you avoid doing expensive operations. First, check if these operations are needed at all. If they are, see if you can store the intermediate results to avoid repeating the expensive operation more than needed.

### Slow Script with Expensive Loop

We'll measure the script speed using the time command

When we call time it runs the command that we pass to it and prints how long it took to execute it. There's three different values. Real, user, and sys. 

Real is the amount of actual time that it took to execute the command

This value is sometimes called wall-clock time because it's how much time a clock hanging on the wall would measure no matter what the computer's doing.

User is the time spent doing operations in the user space. 

Sys is the time spent doing system level operations.

The values of user and sys won't necessarily add up to the value of real because the computer might be busy with other processes.

we'll use the one called pprofile 3. We use the dash f flag to tell it to use the call grind file format and the dash o flag to tell it to store the output in the profile dot out file.

pprofile3 -f callgrind -o profile.out ./program.py

We're going to use kcachegrind to look at the contents, which is a graphical interface for looking into these files.

kcachegrind profile.out

### Parallelizing Operations

 do operations in parallel. That way, while the computer is waiting for the slow IO, other work can take place

 There's actually a whole field of computer science called concurrency, dedicated to how we write programs that do operations in parallel.


Our OS handles the many processes that run on our computer. If a computer has more than one core, the operating system can decide which processes get executed on which core, and no matter the split between cores, all of these processes will be executing in parallel.

Instead, you could split the list of computers into smaller groups and use the OS to call the script many times once for each group. That way, the connections to the different computers can be started in parallel, which minimizes the time but the CPU isn't doing anything.

Another easy thing to do, is to have a good balance of different workloads that you run on a computer.

Threads let us run parallel tasks inside a process.

In Python, we can use the Threading or AsyncIO modules to do this. These modules let us specify which parts of the code we want to run in separate threads or as separate asynchronous events, and how we want the results of each to be combined in the end. 

your script is CPU bound. In this case, you'll definitely want to split your execution across processors

A script is CPU bound if you're running operations in parallel using all available CPU time.

### Slowly Growing in Complexity

store your data in a SQLite file. This is a lightweight database system that lets you query the information stored in the file without needing to run a database server. 

we've gone from hosting the data in a CSV file to having it in a SQLite file then moving it to a database server and finally using a dynamic casher in front of the database server to make it run even faster.

A similar progression can happen on the user facing side of the same project. Initially, we set the Santa service would simply send emails to the people on the list. That's fine if it's a small group and there's one person in charge of the script. But as the project grows more complex, you'd want to have a website for the service to let people do things like check who their assigned person is and create wish lists. Initially, this could just be running on a web server on the same machine as the data. If the website gets used a lot, you might need to add a caching service like Varnish. This would speed up the load of dynamically created pages. And eventually, this still might not be enough. So you need to distribute your service across many different computers and use a load balancer to distribute the requests. You could do this in-house with separate computers hosted at your company, but this means that as the application keeps growing you need to add more and more servers. It might be easier to use virtual machines running in the cloud that can be added or removed as the load sustained by the service changes.

### Dealing with Complex Slow Systems

What do you do if your complex system is slow? As usual, what you want to do is find the bottleneck that's causing your infrastructure to underperform. Is it the generation of dynamic pages on the web server? Is it the queries to the database? Is it doing the calculations for the fulfillment process?

When a database server needs to find data, it can do it much faster if there's an index on the field that you're querying for. On the flip side, if the database has too many indexes, adding or modifying entries can become really slow because all of the indexes need updating.

Now what if when you try to figure out why the service is slow, you see that the CPU on the web serving machine is saturated. The first step is to check if the code of the service can be improved using the techniques that we explained earlier. 

You got it! The local disk I/O latency is causing the application to wait too long for data from disk.

### Using Threads to Make Things Go Faster

importing the futures sub module, which is part of the concurrent module. This gives us a very simple way of using Python threads.

from concurrent import futures

executor = futures.ThreadPoolExecutor()

executor.submit("name of the function", params)

print('Waiting for all threads to finish.')
executor.shutdown

==================

executor = futures.ProcessPoolExecutor()

an executor. This is the process that's in charge of distributing the work among the different workers.

The futures module provides a couple of different executors, one for using threads and another for using processes

So we'll add a message saying that we're waiting for all threads to finish, and then call the shutdown function on the executor. This function waits until all the workers in the pool are done, and only then shuts down the executor.

You nailed it! Memchached is a caching service that keeps most commonly accessed database queries in RAM.

Asyncio is a module that lets you specify parts of the code to run as separate asynchronous events.

## Crashing Programs

### Systems That Crash

The application seems to be crashing randomly but only on that computer. To further reduce the scope, you'll want to know if it's just that application or the whole system. To check this out, you can try moving away the local configuration for the program and using the default configuration instead, or maybe even reinstalling the application.

example that a user asks for your help with a problem on their computer. When you ask for details, the user tells you that the internal billing application crashed while they were trying to generate an invoice for a customer. Now, this could be caused by lots of different things. So what you need to do is reduce the scope of the problem, and remember, you want to start with the actions that are easier and faster to check. As a first step, you tried looking at the logs to see if there's any error that may point to what's happening, but you only find an error saying application terminated and no useful information. So you check if the user can reproduce the problem by doing this same action on a different computer. You ask the user to try this out, and it turns out on a different machine that can generate the invoice just fine. So that means that the problem just has to do with the installation or configuration on that specific computer. Great news. You've already reduced the scope to something machine-specific. Another thing that you might want to check is if this happens reliably. Do all invoice generations fail? Is it confined to one specific product or customer? For this example, let's say that when you ask the user to try generating other invoices, it works just fine even for the same customer. Okay, you think maybe this problem was with a specific order for that specific customer on that specific computer. That's rather suspicious, but not so fast. The user tells you that after creating all the invoices for the day, they tried to generate a report, and the application crashed again. But then it worked the next time. You double-check with other users and find out the application isn't crashing when they use it. So what does this mean? The application seems to be crashing randomly but only on that computer. To further reduce the scope, you'll want to know if it's just that application or the whole system. To check this out, you can try moving away the local configuration for the program and using the default configuration instead, or maybe even reinstalling the application. You might also ask the user if they've seen crashes on any other application. For this example, let's say that reinstalling the application and running it with the default configuration still leads to random crashes. I'm impressed to remember, the user tells you that their web browser also crashed last week when they were using the internal webmail. At this point, the information points to a problem in the overall system, either the hardware or the OS installation. If you have a spare computer available, it might make sense to give one to the user at this point so that they can go back to work while you try to figure out the root cause of the problem. What can you do to further reduce the scope? By now, there's a high likelihood if the problem being hardware related. So one thing you could do is try taking the hard drive out of the computer and putting it into a different computer. This works best when you already have a spare case that you know works well so that you can use it for tests like these. That way you can quickly check if it's a problem with the data and the drive or the rest of the computer. Let's say that after putting the hard drive in the other computer, the applications run without unexpected crashes. This means that some hardware component is at fault. The next step is to find out which one. Given the random crashes, one thing to check would be the RAM. Memory chips deteriorate over time. When they do, the computer might write data to some part of the memory and then get a totally different value when trying to read it back. To check the health of our RAM, we can use the memtest 86 tool to look for errors. We run this tool on boot instead of the normal operating system so that it can access all of the available memory and verify if the data written to memory is the same when it tries to read it back. If the RAM is fine, you can check if the computer's overheating by looking at the sensor data provided by the OS. If that's not the case, check if there's a problem with external devices like a graphics card or sound card. You can do this by disconnecting or replacing the devices present in the computer and checking if the crashes still occur. So what can you do if when putting the hard drive in a separate computer, you still get the strange caches? This means the problem is in the drive itself or the OS installation. As with RAM, our hard drives age. At some point, the data that the computer reads stops matching what was originally stored. Each OS ships its own battery of hard drive checking tools, and you should familiarize yourself with ones in the OS you're working with. You'll want to look at the output of the tools that check the disk for bad sectors, and you'll also want to use these smart tools which can help detect errors and even try to anticipate problems before they affect the computer's performance. What can you do with the hard-drive turns out to be fine? You'd need to look into the possible OS issues, but before doing that, ask yourself, is it worth it? Looking to what's wrong with the installation can take a lot of valuable time. If the installation is easy to replicate, then just reinstalling the OS might be faster and simpler than looking into why it broke. Alright, so that's a glimpse of how you can try to diagnose a system that's unstable and behaving in weird ways. But often, you'll be dealing with a specific application that's misbehaving. In this case, it's almost certainly above in the application's code that's not taking into account a situation that, though unexpected, can sometimes occur. Up next, we'll check out what you can do when that happens.

### 

[MUSIC] When an application crashes and we don't know why we'll want to look for logs that might relate to the failure. To look at logs on Linux will open the system log files and VAR log or the user log files and dot accession errors file. On Mac OS we generally use the console app to look at logs and the event Viewer on Windows. So what kind of data should you look for in these logs most logs have a date and time for each line locked knowing when the application crashed you can look for a log line around that time. And try to find an error message related to the application that crashed. Sometimes the errors will be self-explanatory like permission denied no such file or directory connection refused. Sometimes it will be a cryptic message and you have no idea what it means. Ever we have an error message no matter how weird it seems we can search for it online to try to figure out its meaning. If we're lucky, we might find the official documentation of what that error means and what we can do about it. But even if that's not available, will usually come across posts by others who have tackled a similar error and this additional information can help us understand what's going on. If there are no errors or the errors aren't useful we can try to find out more info by enabling sling debug logging. Many applications generate a lot more output when debugging logging is enabled. We might need to enable it from a setting in the applications configuration file or a command line parameter to pass when running the application manually. By enabling this extra logging information, we can get a better idea of what's actually causing the problem. And what do we need to do if there are no logs or error messages at all. In that case we need to use tools that let us see what going on inside the program. We call that a few are ready. On Linux we use S Trace to see what system calls a programs doing. The equivalent tool is called de trois on Mac OS process monitor is a Windows tool that can also take a peek inside what's going on inside a process on Windows?
Start transcript at 2 minutes 19 seconds

By tracing which system calls a program is doing we can see what files and directories it's trying open what network connections it's trying to make and what information it's trying to read or write. This can give us a better idea of what caused the actual problem. We could find that the problem is caused by a resource not being present that the program expects to be present. Like we saw with the missing directory example in the earlier module or we could find that the program tries to interact with the graphics interface and there isn't any because it's a service running on a server. Or the program tries to open a file but the user running the software doesn't have the necessary permissions. If the application used to work fine and recently started crashing. It's useful to look into what changed in between. The first thing is to check if the issue is caused by a new version of the application itself. Maybe there's a bug in the new version that causes the crash or maybe the way that we're using the application is no longer supported. But that's not the only possible change that could trigger crashes. It could also be that a library or service used by our application changed and they no longer work well together or it could be that there was a configuration change in the overall environment. Like if the user isn't in a specific group anymore or if the files that the application used are in a different location. When trying to figure out what changed logs can also be a useful source of information. In the system log we can check which programs and libraries were recently updated checking for configuration changes might be harder depending on how you manage that configuration. If the settings are managed through a configuration management system and the values are stored in a Version Control System. Then you might be able to look at the history of changes and figure out which one triggered the failure. We call that a few times already how important it is to have a reproduction case for a problem that we're trying to solve. When we're trying to debug an application that crashes finding a reproduction case can help us both understand what's causing the crash and figure out what we can do to fix it. So it's valuable to spend some time figuring out the state that triggers the crash. This includes the overall system environment the specific application configuration the inputs to the application the outputs generated by the application the resources that uses and the services it communicates with. When trying create the reproduction case it might be useful to start from a clean slate and slowly put the pieces in place until the crash triggers. This might include trying out the application with the default configuration instead of the local one or on a freshly installed computer instead of the computer where it's crashing. And remember we want to make the reproduction case as small as possible this lets us better understand the problem and also quickly check if its present or not when we attempt to fix it. And even if we end up unable to fix the issue having a small and simple reproduction case is extremely helpful in reporting a bug to the program's developers. So to sum this up to find the root cause of a crashing application will want to look at all available logs figure out what changed trace the system or library calls the program makes and create the smallest possible reproduction case.

After doing all of this, we should have some idea of what the root cause of the issue is and maybe even how to fix it.

The strategy for fixing problems will depend on whether we can fix the code or not. In our next video, we'll check out what you can do when you can't fix the program and need to work around the issue. And in later videos, we'll deep dive into strategies for fixing faulty code.

### What to do when you can't fix the program?

One of the great things about working in IT is that we can tell the computer what to do and it will follow our orders. When dealing with unexpected behavior in the software written by other people though, we might not always be so lucky. It could be that we're dealing with proprietary software and the source code isn't available at all, or we might have access to the source code but it's written in a language that we don't understand and so we can't change it. No matter the reason, what can you do if you need to fix an application that crashes and you can't change the code. You'll need to figure out a way of working around the problem and avoiding the crash. The actual workaround will depend on what the issue is that you're trying to solve. Let's do a rundown of some of the available options. Say you figured out that the issue was caused by a specific data input that makes the application crash. The crashes only happen when the input isn't in the format the code expects. Some of your systems generate data in XML format which used to work fine with the previous version of the software but the new version now requires all data to be in a YAML format. In this case you can write a script that pre-processes the data and make sure that it's in the format that the program expects. Similarly if the problem is caused by an external service that the application uses and that's no longer compatible, we could write a service to act as a proxy and make sure that both sides see the requests and responses they expect. This type of compatibility layer is called a Wrapper. A Wrapper is a function or program that provides a compatibility layer between two functions or programs so they can work well together. Using Wrappers is a pretty common technique when the expected output and input formats don't match. So if you're faced with some sort of compatibility problem don't be afraid to write a Wrapper to work around it. Another possibility you might need to look at is if the overall system environment is it working well with the application. In this case, you might want to check what environment the applications developers recommend and then modify your systems to match that. This could be running the same version of the operating system using the same version of the dynamic libraries or interacting with the same back end services. Say the application was developed and tested on Windows 7, if you run into problems while trying to run it under Windows 10, you might want to use Windows 7 instead or if the application was developed and tested for Ubuntu and you're having trouble running it under Fedora, you might want to try running it on Ubuntu instead, and what can you do if you can't make the environment match? This could happen, for example, if there's another application that requires a different version of the same library or you can't change a certain configuration setting because it's required to access a different service. In this case, you might want to consider running the application inside a virtual machine or maybe a container. These are two different things but we won't go into details of how they are different here. All you need to know right now is they both let you run the affected application in its own environment without interfering with the rest of the system. This is what we need if we want the environment to be different than the one other Applications are using on the same computer. Sometimes we can't find a way to stop an application from crashing but we can make sure that if it crashes it starts back again. To do this, we can deploy a watchdog. This is a process that checks whether a program is running and when it's not starts the program again. To implement this, we need to write a script that stays running in the background and periodically checks if the other program is running. Whenever the check fails the watchdog will trigger the program to restart. Doing this won't avoid the crash itself. But it will at least ensure that the service is available. This works well for services where availability matters more than running continuously and no matter how you work around the issue, remember to always report the bug to the application developers. As we called out, if you have a good reproduction case for your issue, it makes it easier for the developers to figure out what's wrong and how to fix it. So when you report a bug make sure you include as much information as possible, share good reproduction case and answer the questions that we mentioned earlier on. What were you trying to do? What were the steps you followed? What did you expect to happen? What was the actual outcome? Up next, we'll see how to apply these skills to troubleshoot an application that's crashing.

### Internal Server Error

sudo netstat -nlp | grep :80

A colleague has alerted us that a webpage on our Web server isn't working. As we've done before, we need to figure out what this means exactly. We asked our colleague for more details and they told us that the failing webpage is at site.example.com/blogs. Let's check out if this is failing for us as well. There it is, the server responded with a 500 error. This error usually means that something on the server side of the application crashed, but we have no idea what. We'll need to investigate to find out more information. Let's connect to the Web server and try to figure out what's up.

The first step is looking at logs, as we called out on Linux systems, logs are located in Bar log. To do that, we'll use the date command to check the current date. Let's change into that directory and check out if there are any recent logs about our error and then the Ls -Lt command which sorts the files by the last modified date connecting it to the head command to keep the top 10 lines. We just triggered the error but there doesn't seem to be anything recent in the logs. Just in case, let's check out the last lines insists log using tail.

Nope. Nothing interesting here. We need to figure out how we can get more information, but we don't even know which web surfing software is being used on this computer. But we do know that the Web server is running on port 80, the default web serving port. How can we find which software is listening on port 80? We can use the netstat command which can give us a bunch of information about our network connections depending on the flags we pass. This command accesses a bunch of sockets that are restricted to route the administrator user on Linux. So we'll need to call it with sudo which lets us run commands as root, and then we'll pass a bunch of flags netstat. We'll use -n to print numerical addresses instead of resolving host names. L to only check out the sockets that are listening for connection, and P to print the process ID and name to which each socket belongs. Since we only care about port 80, we'll connect the output to a grep command checking for colon 80.

Great, we got new information. We see that the process listening in port 80 is called "nginx." One of the popular web serving applications out there. We now want to check out the configuration for our site. Configuration files on Linux are stored in the etc directory. So let's look at etc/nginx.

There's a bunch of files here. Lots of different configuration options that you can set in the Web server. We're looking for the configuration related to a specific site. So let's look at etc/nginx sites-enabled.

There are two files here one for the default site and one for the site.example.com site that's the one we want. Let's open it with the VI editor.

There's not a lot here, but at the bottom we see that it says uwsgi_pass, and then the local host address followed by a different port number. It seems that this website isn't being served directly from nginx, instead, the software is passing the control of the connections to uWSGI which is a common solution used to connect a Web server to programs that generate dynamic pages. So let's see if we can find the configuration for that one. We'll exit VI with a colon q and then see if there's anything interesting in etc/uwsgi. Here we only see two directories, apps-available and apps-enabled. Let's say it's an apps-enabled.
Start transcript at 4 minutes 44 seconds

Cool. We found the uWSGI configuration for our site. Let's check it out.

Nice. This file has a lot more information. We see that the main directory for the application is srv/site.example.com that the applications run as the dub-dub-dub Data User and Group, that it's running a Python three script called prod.py that the log is stored in var/log/site.log and a bunch of other things. All right. Let's use this extra information and see if we can find out what's that. Let's exit with colon q once more and then check out that log file. Weird, the log file has a size of zero, that doesn't seem right. Let's see if we can find out anything else by looking at the Python script that's executed by uwsgi srv/site.example.com prod.py.

There's a few different webpages configured in this file. It uses bottle which is a Python module to generate dynamic web pages. At the bottom, we see the configuration for the logs page that's currently failing. Hopefully, a colleague left a comment saying that we can get debugging information by uncommenting the line that calls bottle.debug. That's exactly what we need. To uncomment this line, we need to have write access to the file though, and VI is open in read only mode currently. Let's exit an open again with sudo to be able to modify it.

Okay. We've made the change, let's save it and reload uwsgi as the instructions say. We'll do this by running sudo service uwsgi reload.

We've added debugging information. Hopefully, that will tell us why the pages failing. Let's reload the website and see what happens.

Great news, this time we see a trace back of the error and we see that the issue is that the application is getting a permission denied error when trying to open var/log/site.log. Remember that we thought it was weird that the file was empty, it seems that it's somehow broken. Let's look at it again, this time let's check if there are any other files that start with site.

So there's a site.log file and a site.log.1 file. That's pretty common when using log rotate to rotate the logs and avoid them getting too big. But there's something else afoot here. See how one file belongs to the root user and the other belongs to the dub-dub-dub data user. If you look at the permissions of the file, you might notice that they are set to allow the owner to write them and the owner and the group to read them, but the rest of the users can't access them. We saw earlier that the application is running with the dub-dub-dub data user. So if site.log belongs to the root user, the application won't be able to either read or write to this log file. Ding-ding-ding seems like we found the root cause of our issue. Let's change the owner of the site.log file to fix the immediate problem.

Let's try reloading our page now.

Yes, it works. The log is empty now because the application have not been able to write to it. But if we keep reloading, we'll see how it populates with our entries.
Start transcript at 9 minutes 14 seconds

All right. We've fixed the immediate problem our Web pages working once again, but we still need to take care of the long-term remediation. Why was the ownership of the file wrong? We suspect that there might be something wrong with the log rotate configuration but we'd need to keep looking to find out what's up with that. In this video, we looked into how we can figure out what's up with an application that's failing. We checked out a bunch of different tools and ideas that can help us understand what's going on and get more information until we can find the root cause. I hope we're starting to see how these lessons provide valuable tools for diagnosing and solving issues that will for sure occur at your job. Up next, we have a reading with some links to learn more about different things that can make your computer crash, then a quick practice quiz.

### Accessing Invalid Memory

A program is trying to access invalid memory. 
Using the memory on modern operating systems:
Process asks the operating system for a chunk of memory to store values and do operations on them during the program's execution. 
The OS keeps a mapping table of which process is assigned which portion of the memory.
Processes aren't allowed to read or write outside of the portions of memory they were assigned. 
**Accessing invalid memory** means that the process tried to access a portion of the system's memory that wasn't assigned to it.
The OS raises an error like segmentation fault or general protection faultif the process trying to read or write to a memory address outside of the valid range.. What kind of programming error is this? It typically happens with low-level languages like C or C++ where the programmer needs to take care of requesting the memory that the program is going to use and then giving that memory back once it's not needed anymore. In these languages, the variables that store memory addresses are called pointers. They're just like any other variable and code that can be modified as needed. So if a pointer is set to a value outside of the valid memory range for that process, it will point to invalid memory. If the code then tries to access the memory the pointer points to, the application will crash. Common programming errors that lead to segmentation faults or segfaults include forgetting to initialize a variable, trying to access a list element outside of the valid range, trying to use a portion of memory after having given it back, and trying to write more data than the requested portion of memory can hold. So what can you do if you have a program that's said vaulting? The best way to understand what's going on is to attach a debugger to the faulty program. This way when the program crashes, you'll get information about the function where the fault happened. You'll know the parameters that the function received and find out the address that was invalid. That might already be enough to understand the problem. Maybe a certain variable is being initialized to late or the code is trying to read too many items on a list. If that's not enough, the debugger can give you a lot more detail on what the application is doing and why the memories invalid. For this to be possible, we'll need our program to be compiled with debugging symbols. This means that on top of the information that the computer uses to execute the program, the executable binary needs to include extra information needed for debugging, like the names of the variables and functions being used. These symbols are usually stripped away from the binaries that we run to make them smaller. So we'll need to either recompile the binary to include the symbols, or download the debugging symbols from the provider of the software if they're available. Linux distributions like Debian or Ubuntu ships separate packages with the debugging symbols for all the packages in the distribution. So to debug and application that's segfaulting, we download the debugging symbols for that application. Attach a debugger to it, and see where the fault occurs. When doing this, we might find that the crash happens inside a call to a library function. This is separate from the application itself, so we need to install the debugging symbols for that library. We might need to repeat this cycle a few times before we can identify the portion of the code that's buggy. Microsoft compilers can also generate debugging symbols in a separate PDB file. Some Windows software providers let users download the PDP files that correspond to their binaries to let them properly debug failures. One of the trickiest things about this invalid memory business is that we're usually dealing with undefined behavior. This means that the code is doing something that's not valid in the programming language. The actual outcome will depend on the compiler used, how the operating system assigns memory to processes, and even the version of the libraries in use. A program that runs fine on a computer running Windows trigger a segfault on a computer running Linux and vice versa. When trying to understand problems related to handling invalid memory, valgrind can help us a lot. Valgrind is a very powerful tool that can tell us if the code is doing any invalid operations no matter if it crashes are not. Valgrind lets us know if the code is accessing variables before initializing them. If the code is failing to free some of the memory requested, if the pointers are pointing to an invalid memory address, and a ton more things. Valgrind is available on Linux and Mac OS, and Dr. Memory is a similar tool that can be used on both Windows and Linux. So all of that said, what do we do when we finally discover the cause of the segfaults? You'll want to either change the code yourself or get the developers to fix the problem in the next version. This might sound scary if you've never programmed in the language used by the application. But when you know what's wrong with the code, it's usually not that hard to figure out how to fix it. If a variable is initialized too late, fixing the problem can be as easy as moving the initialization to the right part of the code, or if a loop is accessing an item outside of the length of the list, you might solve the issue by checking that there aren't more iterations than needed. Throughout this program, we've been teaching you these concepts so you can apply them to any piece of code no matter which language the program is using. So don't be afraid to put this into practice. You've got the skills for it. If the program is part of an open source project, you might find that someone else has already done the work, and so you can apply a patch available online. If there's no patch and you can't say you're the bug out yourself, you can always get in touch with the developers and ask a fake and fix the issue and create the necessary patch. In high-level languages like Python, the interpreter will almost certainly catch these problems itself. It will then throw an exception instead of letting the invalid memory access reach the operating system. But still those exceptions can be pretty annoying. We'll talk about those in our next video.

### Unhandled Errors and Exceptions

In our last video, we talked a lot about what happens when a program tries to access invalid memory. Correctly handling memory is a hard problem, and that's why there's a bunch of different programming languages like Python, Java, or Ruby that do it for us. But that doesn't mean programs written in these languages can't trigger weird problems. In these languages, when a program comes across an unexpected condition that isn't correctly handled in the code, it will trigger errors or exceptions. In Python, for example, we could get an index error if we tried to access an element after the end of a list. We might get a type error or an attribute error if we try to take an action on a variable that wasn't properly initialized or division by zero error if we tried to well, divide by zero. When the code generates one of these errors without handling it properly, the program will finish unexpectedly. In general, unhandled errors happen because the codes making wrong assumptions maybe the program's trying to access a resource that's not present or the code assumes that the user will enter a value but the user entered and empty string instead. Or maybe the application is trying to convert a value from one format to another and the value doesn't match the initial expectations. When these failures happen, the interpreter that's running the program will print the type of error, the line that caused the failure, and the traceback. The traceback shows the lines of the different functions that were being executed when the problem happened. In lots of cases, the error message and traceback info already gives us enough to understand what's going on, and we can move on to solving the problem. But sadly, that's not always the case. The fact that a piece of code crashes on one function doesn't mean that the error is necessarily in that function. It's possible, for example, that the problem was caused by a function called earlier which set a variable to a bad value. So the function where the code crashes is just accessing that variable. So when the error message isn't enough, we'll need to debug the code to find out where things are going wrong. For that, we can use the debugging tools available for the application's language. For a Python, program we can use the BDB interactive debugger which lets us do all the typical debugging actions like executing lines of code one-by-one or looking at how the variables change values. When we're trying to understand what's up with a misbehaving function on top of using debuggers, it's common practice to add statements that print data related to the codes execution. Statements like these could show the contents of variables, the return values of functions or metadata like the length of a list or size of a file. This technique is called print f debugging. The name comes from the print f function used to print messages to the screen in the C programming language. But we can use this technique in all languages, no matter if we use print, puts, or echo to display the text on the screen. Let's take this one step further. When changing code to print messages to the screen, the best approach is to add the messages in a way that can be easily enabled or disabled depending on whether we want the debug info or not. In Python, we can do this using the logging module. This module, lets us set how comprehensive we want our code to be. We can say whether we want to include all debug messages, or only info warning or error messages. Then when printing the message, we specify what type of message we're printing. That way, we can change the debug level with a flag or configuration setting. So you figured out why the unexpected exception was thrown, what do you do next? The solution might be fixing the programming error like making sure variables are initialized before they're used or that the code doesn't try to access elements after the end of a list. Or it could be that certain use cases that hadn't been considered needs to be added to the code. In general, you'll want to make the program more resilient to failures. Instead of crashing unexpectedly, you want the program to inform the user of the problem and tell them what they need to do. For example, say you have an application that crashes with a permission denied error. Rather than the program finishing unexpectedly, you'll want to modify the code to catch that error and tell the user what the permission problem is so they can fix it. For example, unable to write new files and temp, make sure your user has bright permissions on temp. In some cases, it doesn't make sense for our program to even run if certain conditions aren't met. In that case, it's okay for the program to finish when the error is triggered. But again, it should do so in a way that tells the user what to do to fix the problem. For example, if it's critical for an application to connect to a database but the database server isn't responding, it makes sense for the application to finish with an error saying unable to connect to the database server. It also makes sense to include all details of the attempted connection like the host name, the port, or the username used to connect. So to recap, if your program is crashing with an unhandled error, you want to first do some debugging to figure out what's causing the issue. Once you figured it out, you want to make sure that you fix any programming errors and that you catch any conditions that may trigger an error. This way, you can make sure the program doesn't crash and leave your users frustrated. Up next, we'll talk a bit about what you can do when you're trying to fix someone else's code.

### Fixing Someone Else's Code

In our IT jobs, it's pretty common to have to fix problems and code that we didn't write ourselves. It might be because we're working with a program that's open-source or with a program that was developed by someone else inside the company. When this happens, we need to spend some time getting acquainted with the code so that we can understand what's going on. Let's do a rundown of some things that can help us with that. If the code has comments and the functions are well-documented, reading these is a great place to start when trying to figure out what's going on. Remember way back in the course when we first introduced Python, we talked about the importance of developing good habits when we're writing code. Writing good comments is one of those good habits that pays off when trying to understand code written by others and also your past self. Unfortunately, a lot of code doesn't include enough comments, leaving us to try to understand it without enough context. If that's the case, you can improve things by adding comments as you read the code and figure out what it's doing. Writing these comments help you solidify your understanding. If you contribute those comments back to the original developers, you can help anybody else trying to understand the code. Another thing that can help to understand someone else's code is reading the tests associated to the code. Well-written tests can tell us what each function is expected to do. Looking at the existing tests can show us which use cases weren't taken into account. But what if there aren't enough tests? Just like with writing extra comments, writing some tests of your own can help you better see what the code is supposed to do and improve overall quality of the code. This can also be really useful when modifying the original code. To ensure that changes you make, don't break the rest of the functionality. In my job, I need to make changes to code written by other people a lot. I definitely read the comments and sometimes reference the tests too. But in the end, to really understand what's going on, I just have to read through the code. But how do you even start reading through someone else's code? This depends a bit on personal preference and the size of the project. If there are only a couple of 100 lines of code, it's feasible to read all of them. But when the project has thousands or tens of thousands of lines of code, you can't really read the whole thing. You'll need to focus on the functions or modules that are part of the problem that you're trying to fix. One possible approach in this case, would be to start with the function where the error happened, then the function or functions that call it, and so on until you can grasp the contexts that led to the problem. While this is of course much easier if it's in a programming language that you're familiar with, you don't need to be an expert in the language to fix a bug in the program. If you've come across an error and debug the issue well enough to understand what's going on, you might be able to fix the problem even if you've never seen that language before. This is one of those skills that gets better with practice. So it might make sense to you to start practicing before you need to fix a problem in the code. Take a program that you both use and have access to its code and figure out how it does a specific action. Follow the code until you really understand what's going on. For example, you could take the web server software you're using and check out how it parses its configuration files, or take a look at one Python module you like, like Python Request for example, and figure out how it processes the data it receives. Doing this, you can get used to reading code written by others and understanding what it's doing. Another option is to pick an open-source project that you use. Look at the list of open issues and to have a go at fixing an easy one. To do that, you'll need to find your way around the code, understand what it's doing and what to change. By practicing doing this, you'll improve your ability to quickly figure out what the code does and what needs to be changed, while helping improve the project's overall quality. Up next, we'll get some practice fixing issues and a couple of different programs that crash.

### Debugging a Segmentation Fault

Core files store all the information related to the crash so that we or someone else can debug what's going on.

In our last video, we discussed how systems that grow in usage also grow in complexity. In large complex systems, we have lots of different computers involved. Each one doing a part of the work and interacting with the others through the network. For example, think of an e-commerce site for your company. The web server is the part of the system that directly interacts with external users. Another component is the database server, which is accessed by the code that handles any requests generated from the website, and depending on how the whole system is built, you might have a bunch of other services involved doing different parts of the work. There could be a billing system that generates invoices once orders are placed. A fulfillment system used by the employees preparing the orders for customers. A reporting system that once a day creates a report of all the sales placed and possibly more. On top of this, you should probably have backup, monitoring, testing infrastructure, and so on. A system like this can be tricky to debug and understand. What do you do if your complex system is slow? As usual, what you want to do is find the bottleneck that's causing your infrastructure to underperform. Is it the generation of dynamic pages on the web server? Is it the queries to the database? Is it doing the calculations for the fulfillment process? Figuring this out can be tricky. So one key piece is to have a good monitoring infrastructure that lets you know where the system is spending the most time. Saying notice that getting the web pages is pretty slow. But when you check the web server, you see that it's not overloaded. Instead, most of the time is spent waiting on network calls, and when looking at your database server, you find that it's spending a lot of time on Disk I/O. This shows that there's a problem with how the data is being accessed in the database. One thing to look at is the indexes present in the database. When a database server needs to find data, it can do it much faster if there's an index on the field that you're querying for. On the flip side, if the database has too many indexes, adding or modifying entries can become really slow because all of the indexes need updating. So we need to look for a good balance of having indexes for the fields that are actually going to be used. If the problem is not solved by indexing and there are too many queries for the server to reply to all of them on time, you might need to look into either caching the queries or distributing the data to separate database servers. Now what if when you try to figure out why the service is slow, you see that the CPU on the web serving machine is saturated. The first step is to check if the code of the service can be improved using the techniques that we explained earlier. If it's a dynamic website, we might try adding caching on top of it. But if the code is fine and the cache doesn't help because the problem is that there's just too many requests coming in for one machine to answer all of them, you'll need to distribute the load across more computers. To make this possible, you might need to reorganize the code so that it's capable of running in a distributed system instead of on a single computer. This might take some work, but once you've done it, you can easily scale your application to as many requests as needed by adding more computers to the system, and finally, make sure that you actually need to do whatever you're doing. Lots of times, as projects evolve, we're left with a scary monster of layer after layer of complex code. If we think about what our system is doing for a few minutes, we might end up discovering that there's a whole piece that wasn't needed at all and it was making our servers do unnecessary work all along. If all of this is starting to sound too difficult and scary, don't worry. Remember that if you ever need to deal with such complex systems, one of your best tools is to ask your colleagues for help. Up next, we'll try our hand at solving a real life problem with something complex.

### Using Threads to Make Things Go Faster

[MUSIC] Our company has an e-commerce website that includes a bunch of images of the products that are up for sale. There's a rebranding coming up, which means that all of these images will need to be replaced with new ones. This includes both the full-size images and the thumbnails. We have a script that creates the thumbnails based on the full-size images. But there's a lot of files to process, and our script is taking a long time to finish. It looks like it's time to take it up a notch and use something better to do the resizing. We'll start by trying out the current script as-is using a set of 1,000 test images. There's more images to convert, but it'll be easier to test the speed of our script with a smaller batch. We'll execute our program using the time command to see how long it takes.

It took about two seconds for 1,000 images. This doesn't seem too slow, but there's tens of thousands of images that need converting, and we want to make sure that the process is as fast as possible. Let's try making this go faster by having it process the images in parallel. We'll start by importing the futures sub module, which is part of the concurrent module. This gives us a very simple way of using Python threads.

To be able to run things in parallel, we'll need to create an executor. This is the process that's in charge of distributing the work among the different workers. The futures module provides a couple of different executors, one for using threads and another for using processes. We'll go with the ThreadPoolExecutor for now.

Now the function that does most of the work in this loop is process_file. Instead of calling it directly in the loop, we'll submit a new task to the executor with the name of the function and its parameters.

Our for loop now creates a bunch of tasks that are all scheduled in the executor. The executor will run them in parallel using threads. An interesting thing that happens when we use threads is that the loop will finish as soon as all tasks are scheduled. But it will still take a while until the tasks complete. So we'll add a message saying that we're waiting for all threads to finish, and then call the shutdown function on the executor. This function waits until all the workers in the pool are done, and only then shuts down the executor.
Start transcript at 3 minutes 29 seconds

All right, we've made the change, let's save our script and test it out.

Our script now takes 1.2 seconds. That's a nice improvement over the two seconds we saw before. See how the user time is higher than the real time? By using multiple threads, our script is making use of the different processors available in the computer. And this value shows the time used on all processors combined. What do you think will happen if we try to use processes instead of threads? Let's try this out by changing the executor that we're using.

By changing the executor to the ProcessPoolExecutor, we tell the futures module that we want to use processes instead of threads for the parallel operations. Let's save and try this one out now.

Wow, this is now taking less than a second to finish, and the user time has gone up even more. This is because, by using processes, we're making even more use of the CPU. The difference is caused by the way threads and processes work in Python. Threads use a bunch of safety features to avoid having two threads that try to write to the same variable. And this means that when using threads, they may end up waiting for their turn to write to variables for a few milliseconds, adding up to the small difference between the two approaches.

In this video, we looked into how we can add threading support to a Python script to make better use of our processor power. There's still more improvements that we can make to our script, like checking if the thumbnail exists and is up to date before doing the conversion. Or adding a second progress bar while waiting for tasks to finish, to make it clear that our script is doing its job. We won't go into those here, but if you're interested, you can explore those possibilities on your own. Up next, another reading with pointers to more information, followed by the last practice quiz of the module.

### Crashes in Complex Systems

Up to now we've talked about how to diagnose and fix errors that are confined to one computer. That's a common case for computers that are used by a single user. But once we start going into complex systems that involve many different services, we'll need to take a look at the bigger picture and have different computers interact with each other. Say you're in charge of the e-commerce site for your company. The page as seen by the users recently started responding with internal server error to about 20% of all requests. How do you figure out what's going on? You want to apply the same principles that we saw for troubleshooting a problem on one computer, but this time at a larger scale. So you'll want to check the log messages in the servers providing the service, and see if you find any additional information pointing to what's causing the issue. You'll want to find any log specific to the service that's failing, and also look at the general system logs to see if there's a problem affecting the server in general. For this example, let's say you find a bunch of entries in the logs that say, invalid response from server. That's not a great error message. You don't know what the request was or what the response was, but it's at least a clue that whatever's happening is related to some other service in the overall system. We said that this started failing recently, so it might make sense to figure out what changed between what it was working correctly and when it started to fail. Was there a new version of the system deployed? Were there any relevant changes regarding the requests? Let's say this is happening on a Tuesday morning, and the latest release of this service was the previous week. Things were working fine until today, and the requests seemed normal, nothing out of the ordinary. So the service itself is probably okay, but what about the other services involved in the system? Was there a new version of one of the underlying systems, like the database, the authentication service, or some other back-end server like the inventory, billing, or procurement systems? Looking at recent changes, you see that there were a bunch of changes made earlier in the day to the load balancer used between the front-end and the back-end services. Since the only clue you have is that the response from the service was invalid, you're not sure that these changes are at fault, but they sure seem suspicious. Whenever possible, the best strategy is to roll back the changes that you suspect are causing the issue, even if you aren't 100% sure if this is the actual cause. If your infrastructure allows easy rollbacks, try that before doing any further investigation. Why? Because that way, you'll restore the service back to health if it was the cause, or you'll eliminate this change as a possible cause if doing the rollback doesn't help. Whether you do the rollback or not, when coming across unhelpful error messages, it's a good idea to improve them. Instead of the error just saying that the response is invalid, change it to include what the request and the response were, and why the response was invalid. That way, the next time you're trying to debug a similar issue you already have more information to work with. For this example, if the error had included this information you'd have seen that the invalid response was a 404 error. This was caused by having a server added to the pool as part of the inventory system, but the server actually belonged to the procurement system. Now, say a couple of weeks later you see that again, there are a bunch of internal server errors in the same service. It might be tempting to assume that it's the load balancer's fault once again, but by now you know that you should always look at the logs first and see what you find. There's no reason why the error should be the same this time. When looking at the logs you may notice, for example, that only one of the front-end servers is actually affected by the problem. All the other machines are serving their content successfully. In a case like this, you'd start by first removing the machine from the pool of servers that can provide this service. That way, you avoid users getting any more errors. Well, you can investigate what's going on with the broken machine. As you've probably realized by now, when dealing with complex systems like these having good logs is essential to understanding what's going on. On top of that, you'll want to have good monitoring of what the service is doing and use version control for all changes so that you can quickly check what's changed and roll back when needed. It's also important that you can very quickly deploy new machines when necessary. This could be achieved by either keeping standby servers, in case you need to use them, or by having a tested pipeline that allows you to deploy new servers on demand.

A lot of companies today have automated processes for deploying services to virtual machines running in the cloud. This can take a bit of time to set up, but once you've done that you can very easily increase or reduce the amount of servers you're using. This can help a lot when investigating and solving problems. But one thing to take into account when the servers are running as virtual machines, especially if they're running in the cloud, is that there might be external limits apply to these services. Resources, like the available CPU time, RAM, or network bandwidth, might be artificially capped. And not only that, the use of certain external services can also be limited, like how many database connections you can have at the same time or how much data you can store. If these limits are causing problems with your application, you might need to rethink how you use your resources.

We've covered a bunch of techniques that you can use when facing a problem in a complex system. Looking at the available logs, figuring out what changed since the system was last working, rolling back to a previous state, removing faulty servers from the pool, or deploying new servers on demand. Up next, we'll explore a different part of dealing with bigger incidents, communication and documentation.

### Communication and Documentation During Incidents

Until now, we've discussed how we can troubleshoot computers or systems with a specific issue. We've covered how we can get enough information so we can identify the root cause, and then apply the necessary remediation. There's another aspect to all of this. What is related to how we handle the communication with those affected by the issue and how we distribute tasks when addressing large issues as a team. Armed with what you've learned so far and your past experience, you might do a great job troubleshooting a problem. But if you drop the ball when it comes to communicating what you're doing, you could end up with a bunch of frustrated users calling you to find out what's going on. If you don't write down what you've tried or how you fix the problem, you risk for getting some important details and wasting a lot of valuable time when you need to revisit an issue. When working on a problem, it's always a good idea to document what you're doing in a bug or ticket. If there's no such system at your company, then use a doc, a text file, or Wiki, or whatever you have access to. Documenting what you do, lets you keep track of what you've tried and what the results were. This might seem unnecessary. But after a whole day of troubleshooting a problem, it's pretty common for us to forget what we've tried or what was the outcome of a specific action. On top of that, having all this info available in some electronic forum lets you easily share all the data you've collected with other team members. If for example, you brought something back which turned out to be unrelated. Having the whole process document it, helps you remember to roll forward again. While you're working on a problem, it's important to communicate clearly with those affected by the issue. They want to know what you figured out about the problem, what the available workarounds are, and when they can expect the next update. If you don't know what the problem is, it's hard to give an estimation of when you'll have it fixed. But you can still provide timely updates about the work you're doing. This kind of regular communication is helpful no matter the size of the incident. But the more people affected, the more you'll want to provide regular updates with clear instructions of what users can do and what they can expect as a solution. That way, they can better plan and organize their time. If access to the Internet is down, you want to let people know if they can expect to fix in one or two hours or if it's going to take the whole day. This info can make a difference between people choosing to discuss issues in person for a couple of hours or deciding to work from home. If the issue is big enough that you're involving more people in finding a solution, you should agree on who's going to work on which tasks. For example, you could have someone working on finding out a temporary workaround, while someone else is in charge of understanding the root cause of the problem and finding the long-term remediation. Or if there are lots of possible causes for the issue, you could divide the causes among the team members and have them work on those in parallel. On top of people looking for the root cause and a solution, you want to have a person in charge of communicating with the people affected. This lets the team avoid forgetting to update the tracking issue or even worse providing contradictory information. This communications lead needs to know what's going on and provide timely updates on the current state and how long until the problem's resolved. They can act as a shield for questions from users letting the rest of the team focus on the actual problem. Similarly, there should be one person in charge of delegating the different tasks to the team members. This person sometimes called the Incident Commander or Incident Controller needs to look at the big picture and decide what's the best use of the available resources. They can make sure that there's no duplication of work among team members and that only one person is modifying the production system at a time. Having multiple people make overlapping changes to the system could lead to confusing results, making the outage even longer. Of course, this division of roles makes the most sense when there's a large incident and there's a big team working on figuring out the solution. If it's only two or three people working on the problem, it's still important to agree who will work on what but you probably don't need to use any special role names to do that. Once the issue has been resolved, it's super-important to sum up the information that was helpful. The most important information that you'll want to include are the root cause, how you diagnose the problem and found that root cause, what you did to fix the issue and what needs to be done to prevent the problem from happening again. Depending on the size of the issue and the number of people affected, this summary could just be the last update to the bug or ticket that you use to keep track of your work, or it could be a full postmortem. What's a postmortem, and how do you write when you ask? Well, that's coming up in our next video.

### Writing Effective Postmortems

In our last video, we talked about the importance of communication and documentation when troubleshooting incidence. We called out that if the issue is big enough, we might want to document what happened in a postmortem. Postmortems are documents that describe details of incidence to help us learn from our mistakes. When writing a postmortem, the goal isn't to blame whoever caused the incident, but to learn from what happened to prevent the same issue from happening again. To do this, we usually document what happened, why it happened, how it was diagnosed, how it was fixed, and finally figure out what we can do to avoid the same event happening in the future. Remember the main goal is to learn from our mistakes. Writing a postmortem isn't about getting someone fired but about making sure that next time we do better. Writing postmortems after dealing with incidence is important because it helps us avoid dealing with them again or at least learn how to deal with the next incident better. While Postmortems are super useful with large incidence, you don't need to wait until something huge happens to write your first postmortem. You can practice riding them for any kind of event where there's something to be learned no matter how small. That way, when you need to write a postmortem after a big incident, you know how to concentrate on the things that matter the most. What you can learn from the problem and how you can prevent it in the future. So what should you write in a postmortem? The exact structure might vary depending on preference and the type of incident that you're dealing with. In general, you'll want to include the details of what caused the issue, what the impact of the issue was, how it got diagnosed, the short-term remediation you applied, and the long-term remediation you recommend. If the document is long and you're going to share it with a lot of people, you want to include a summary that highlights the root cause, the impact, and what needs to be done to prevent the issue from happening again. It's useful to include what went well in postmortems too. When working on a problem, we might realize that it would have been much worse if we didn't have certain tools or systems available. For example, we might say that we were able to solve the problem quickly by doing a roll back to the previous version or that we caught the issue before users even noticed it because we had good monitoring and alerting. Noting the things that went well helps us show that our systems are effective and justifies keeping those systems running. Writing a postmortem can sometimes help you understand the services that you're working with much better. Earlier this year, a service I worked on had a large outage and I needed to provide information on what happened. To do this, I needed to parse through hundreds of gigabytes of archive logged data to show that certain data had never been received by the service. Doing this, I realized that I needed to improve the data logged by our tools to give better information and have better reporting. You can even practice writing postmortems outside of the IT context. Like, if you bake cookies and they don't turn out as great as you wanted them to, document what you did, what went wrong, what went right, and how you can improve the results in the future. You can do this with any hobby that you have. Maybe photography, 3D printing or brewing your own beer. You don't always need to write the whole thing down. Sometimes a mental note is enough, like if you bike to work and realize wearing your backpack hurts your shoulders, make a mental note to add a basket to your bike. So you can put your backpack there next time, or if on your last trip it was colder than expected and you forgot to bring a jacket, make a mental note that next time you should check the weather before you leave. Once again, remember that the most important part of the postmortem is what we can learn for the future. So if instead of writing a whole document you're creating a one paragraph summary of the incident. Remember to focus that paragraph on what you can do better, not on whatever mistake caused the incident. Up next, we've got a quick quiz to check that everything still make sense.

## Managing Recources

### Memory Leaks and How to Prevent Them

Garbage collector, that's in charge of freeing the memory that's no longer in use.

Most applications need to store data in memory to run successfully. We called that earlier, how processes interact with the OS to request chunks of memory, and then release them when they're no longer needed. When writing programs in languages like C, or C plus plus, the programmer is in charge of deciding how much memory to request, and when to give it back. Since we're human, we might sometimes forget to free memory that isn't in use anymore, this is what we call a Memory leak. A memory leak, happens when a chunk of memory that's no longer needed is not released. If the memory leak is small, we might not even notice it, and it probably won't cause any problems. But, when the memory that's leaked becomes larger and larger over time, it can cause the whole system to start misbehaving, not cool memory leak, not cool. When a program uses a lot of RAM, other programs will need to be swapped out and everything will run slowly. If the program uses all of the available memory, then no processes will be able to request more memory, and things will start failing in weird ways. When this happens, the OS might terminate processes to free up some of the memory, causing unrelated programs to crash. You might be thinking why should I care if I don't plan to code in C or C plus plus, it's true, the languages like Python, Java, or Go manage memory for us, but things can still go wrong if we don't use the memory correctly. To understand how this works, let's look into what these languages do. First, they request the necessary memory when we create variables, and then they run a tool called Garbage collector, that's in charge of freeing the memory that's no longer in use. To detect when that's the case, the garbage collector looks at the variables in use and the memory assigned to them and then checks if there any portions of the memory that aren't being referenced by any variables. Say for example, you create a dictionary inside a function, use it to process a text file, calculate the frequency of the words in the file, and then return the word that was used the most frequently. When the function returns, the dictionary is not referenced anymore. So the garbage collector can detect this and give back the unused memory, but if the function returns the whole dictionary, then it's still in use, and the memory won't be given back until that stops being the case. When our code keeps variables pointing to the data in memory, like a variable in the code itself, or an element in a list or a dictionary, the garbage collector won't release that memory. In other words, even when the language takes care of requesting and releasing the memory for us, we could still see the same effects of a memory leak. If that memory keeps growing, the code could cause the computer to run out of memory, just like a memory leak would. The OS will normally released any memory assigned to a process once the process finishes. So memory leaks are less of an issue for programs that are short lived, but can become especially problematic for processes that keep running in the background. Even worse than these, are memory leaks caused by a device driver, or the OS itself. In these cases, only a full restart of the system releases the memory. Say you notice that your computer seems to run out of memory a lot, you look at the running programs over the course of some time, and realize that there's a process that keeps using more and more memory as the hours pass. If you reset that process, it begins with a very small amount of memory, but quickly requires more and more. If that's the case, it's pretty likely that this program has a memory leak. So let's jog its memory, what can we do if we suspect a program has a memory leak? We can use a memory profiler to figure out how the memory is being used. As what debuggers will have to use the right profiler for the language of the application. For profiling C and C plus plus programs, we'll use Valgrind which we mentioned in an earlier video. For profiling a Python, there are bunch of different tools that are disposal, depending on what exactly we want to profile. We can be as detailed as profiling the memory usage of a single function, or as big picture as monitoring the total memory consumption over time. Using profilers, we can see what structures are using the most memory at one in time or take snapshots at different points in time and compare them. The goal of these tools is to help us identify which information we're keeping in memory that we don't actually need. It's important that we measure the use of memory first before we try to change anything, otherwise we might be optimizing the wrong piece of code. Sometimes we need to keep data in memory, and that's fine, but you want to make sure that you're only keeping the data that you actually need, and that you've let go of anything you won't be using, that way the garbage collector can give that memory back to the OS. Of course, if you check that you're using the memory correctly, but still find that your exhausting available RAM, it might be time for an upgrade. Did you commit all that to memory? Don't forget, there's a lot more to say about memory profiling than we have time to cover it, but we've included links to more information about some of these profiling tools in the next reading. Up next, we'll talk about a different resource that might need some special care, disk space.

### Managing Disk Space

sudo lsof | grep deleted

Another resource that might need our attention is the disk usage of our computer. Programs may need disk space for lots of different reasons. Installed binaries and libraries, data stored by the applications, cached information, logs, temporary files or even backups. If our computers running out of space, it's possible that we're trying to store too much data in too little space. Maybe we have too many applications installed, or we're trying to store too many large files in the drive. But it's also possible that programs are misusing the space allotted to them, like by keeping temporary files or caching information that doesn't get cleaned up quickly enough or at all. It's common for the overall performance of the system to decrease as the available disk space gets smaller. Data starts getting fragmented across the desk, and operations become slower. When a hard drive is full, programs may suddenly crash, while trying to write something into disk and finding out that they can't. A full hard drive might even lead to data loss, as some programs might truncate a file before writing an updated version of it, and then fail to write the new content, losing all the data that was stored in it before. Yikes. If it gets to this point, we'll probably see some error, like no space left on device when running our applications or in the logs. So what do you do if a computer runs out of disk space? If it's a user machine, it might be easily fixed by uninstalling applications that aren't used, or cleaning up old data that isn't needed anymore. But if it's a server, you might need to look more closely at what's going on. Is the issue that you need to add an extra drive to the server to have more available space, or is it that some application is misbehaving and filling the disk with useless data? To figure this out, you want to look at how the space is being used and what directories are taking up the most space, then drill down until you find out whether large chunks of space are taken by valid information or by files that should be perched. For example, on a database server, it's expected that the bulk of the disc space is going to be used by the data stored in the database. A mail server, it's going to be the mailboxes of the users of that service. But if you find that most of the data is stored in logs or in temporary files, something has gone wrong. One common pattern of misbehavior is a program that keeps logging error messages to the system log over and over. This can happen for lots of different reasons. For example, the OS might keep trying to start a program that fails because of a configuration problem. This will generate a new log entry with every retry, and can take up a lot of space if there are several retries per second, or it could be that the server has a lot of activity and the logs are real. But there are just too many of them. In that case, you might want to look on the tweaking, the configuration of the tools that rotate the logs more frequently, to make sure that you're keeping only what you need. In other cases, the disk might get full due to a program generating large temporary files, and then failing to clean those up. For example, an application might clean up temporary files when shutting down cleanly, but leave them behind if it crashes. Or it could simply be a programming error of creating temporary files and never cleaning them up. In a case like this, you'll ideally have some housekeeping to fix the program, and delete those files correctly. But if that's not possible, you might need to write your own script that gets rid of them. A situation that might be tricky to debug is when the files taking up the space or deleted files. I'm sure you're wondering, how can deleted files take up space? Great question. Well, if a program opens a file, the OS lets that program read and write in the file regardless of whether the file is marked as deleted or not. So lots of programs delete the temporary files they create right after opening to avoid issues with failing to clean them up later. That way, the process can read from and write to the file while the file is open. Then when the process finishes, the file gets closed and actually deleted. Now, this system is widely used and works fine for most processes. But if for some reason, this temporarily deleted file starts becoming super large, it can end up taking up all the available disk space. If that happens, we'll be left scratching our heads when trying to figure out where most of the data went, since we won't see these deleted files. To check for the specific condition, we need to list the currently opened files, and comb for the ones that we know are deleted. We include pointers to the commands for how that works in the next reading. Of course, there are all kinds of other reasons why the disk may be getting too full. Just remember that whenever this happens, your process will remain the same. You'll need to spend some time looking into what's using the disk. Check to see if it's expected or an anomaly, figure out how to solve it, and most important of all, how to prevent it from happening again? Up next, we'll discuss yet another resource that might cause some trouble. The network.

### Network Saturation

The two most important factors that determine the time it takes to get the data over the network are the latency and the bandwidth of the connection. The latency is the delay between sending a byte of data from one point and receiving it on the other. This value is directly affected by the physical distance between the two points and how many intermediate devices there are between them. The bandwidth is how much data can be sent or received in a second. This is effectively the data capacity of the connection. Internet connections are usually sold by the amount of bandwidth the customer will see.

When you work in IT, you interact with services all over the Internet. At one moment, you might connect to a service running on your local network and the next use another service running in a data center located on a different continent. If your network connection is good, you might not be able to tell the difference where the website you're browsing is hosted. But if you're dealing with a network service that isn't exactly up to speed, you might need to get more details about the connection you're using. The two most important factors that determine the time it takes to get the data over the network are the latency and the bandwidth of the connection. The latency is the delay between sending a byte of data from one point and receiving it on the other. This value is directly affected by the physical distance between the two points and how many intermediate devices there are between them. The bandwidth is how much data can be sent or received in a second. This is effectively the data capacity of the connection. Internet connections are usually sold by the amount of bandwidth the customer will see. But it's important to know that the usable bandwidth to transmit data to and from a network service will be determined by the available bandwidth at each endpoint and every hop between them. To understand how latency and bandwidth interact, think about what happens when you try to visit a website over the Internet. If the web server is hosted somewhere across the ocean, the latency might be a 100 milliseconds or so. That's the time it takes for your request to reach the server. The server will then generate a response and send it back to you. The first bytes of the response will again take a 100 milliseconds to zap across the pond to your computer. Once the response is on its way, the time it takes for the rest of the data to arrive is determined by the bandwidth. If the available bandwidth between the two points is 10 megabits per second, you'll be able to receive 1.25 megabytes every second. So for a website of about one megabyte of content, that large initial latency will be noticeable, since it's an extra 20 percent on top of the total time to download it. But if the content is 10 megabytes or more, the initial latency will be less than five percent of the total time to download it. So it matters less. Let's say you're trying to figure out why a network connection isn't going as fast as you want. Remember that if you're transmitting a lot of small pieces of data, you care more about latency than bandwidth. In this case, you want to make sure that the server is as close as possible to the users of the service, aiming for a latency of less than 50 milliseconds if possible, and up to a 100 milliseconds in the worst-case. On the flip side, if you're transmitting large chunks of data, you care more about the bandwidth than the latency. In this case, you want to have as much bandwidth available as possible regardless of where the server is hosted. What do we mean by bandwidth available? Computers can transmit data to and from many different points of the Internet at the same time, but all those separate connections share the same bandwidth. Each connection will get a portion of the bandwidth, but the split isn't necessarily even. If one connection is transmitting a lot of data, there may be no bandwidth left for the other connections. When these traffic jams happen, the latency can increase a lot because packets might get held back until there's enough bandwidth to send them. You've probably experienced this already on your own computer. If you've ever run several applications using the same network at once, the overall connection speed may have seem slower. You can check out which processes are using the network connection by running a program like iftop. This shows how much data each active connection is sending over the network. You might also have noticed that the more users sharing the same network, the slower the data comes in. This is true for home connections and office connections alike. No matter how much bandwidth you have, it's a limited resource. So you'll need to be careful with how you share it among its users. If some applications are using so much bandwidth that others can't transmit anymore data, it's possible to restrict how much each connection takes by using traffic shaping. This is a way of marking the data packets sent over the network with different priorities. To avoid having huge chunks of data, use all the bandwidth. By prioritizing accordingly, processes that send and receive small packets can keep working fine, while processes that need the most bandwidth can use the rest. There's also a limit to how many network connections can be established on a single computer. This isn't usually a problem, but there could be bugs in the software that causes it to open way too many connections, or keep old connections open even if they're no longer in use. If this happens on a server, no new users will be able to connect to it until whatever is keeping those connections open closes them. Up next, we'll try our hand at solving another real-world example. This time, we'll be dealing with a memory leak and adjusting our program to make better use of our resources.

### Dealing with Memory Leaks (Not formatted)

* The scroll buffer is that nifty feature that lets us scroll up and see the things that we executed and their output. 

* Reasons why an app requests a lot of memory:
    * The program needs it to complete its task.
    * Misbehaving software misbehaving.

* **od -cx /dev/urandom** - takes the random numbers generated by the urandom device and shows them as both characters and hexadecimal numbers. 

* Pressing "**Shift M**" we tell **top** to order the programs by how much memory they are using.

* The output of top:
    * **RES** is the dynamic memory that's preserved for the specific process. 
    * **SHR** is for memory that's shared across processes.
    * **VIRT** lists all the virtual memory allocated for each process.
    
* Virtual memory includes:
    * process specific memory
    * shared memory
    * and other shared resources that are stored on disk but maps into the memory of the process.

   * RES column(in **top**) is usually the one that indicates a problem.

* Comparing the output of top to what it used to be a while back is usually how any investigation into a **memory leak** starts.

* **Memory profiler** module is one of the many different memory profilers available for Python.

* To analyze the memory consumption of the main function definitionadded we need to add this app profile label before it. 

* A decorator is used in Python to add extra behavior to functions without having to modify the code.

* The **memory profiler** gives us info about which lines are adding or removing data from the memory used by the program. 

* **Memory profiler** output:

    * The first column shows us the amount of memory required when each line gets executed

    * The second one shows the increase in memory for each specific line.


### Getting to the Important Tasks

In earlier videos, we discussed how to make better use of the resources available on our computers and systems, like the CPU, the memory, the disk, the network, and so on. But, there's another resource that's even more valuable in our day to day, our time. As humans, we want to make sure that we spend our time doing meaningful activities, like work that we enjoy, and earning the satisfaction of a job well done. When working, we need to optimize the time we spend to bring the most value to the company. Finding the right balance is hard, but that's what we're here for. From updated calendars, to social media detoxes, there's lots of different ways to optimize our time. One that's super effective when working in IT is **the Eisenhower Decision Matrix**.

**the Eisenhower Decision Matrix** is a super effective way to optimize our time when working in IT.

When using this method, we split tasks into two different categories: urgent and important. There are tasks that are important and urgent. Draw alarm bells around them if you'd like because these need to be done right away. For example, if the company's Internet connection is down, it's both urgent and important to get it back up as soon as possible. Some tasks are important, but not urgent, so they need to get done at some point even if it takes a while to complete them. For example, as a follow-up to the network being down, it would be important to make sure that there's a backup network connection so that if the existing one is ever down again, the company can stay connected using the backup. Other tasks might seem urgent, but aren't really important. A lot of the interruptions that we need to deal with are in this category. Answering email, phone calls, texts, or instant messages feel like something that we need to do right away. But most of the time are not really the best use of our time. Finally, there's a whole category of tasks that are neither important nor urgent. These are distractions and time wasters, they shouldn't be done at all. These include: meetings where nothing useful is being discussed, email threads that lead to nowhere, office gossip, no thanks, and any other tasks that eat up our time without giving anything valuable in return. In general, to make the most of our time, we need to make sure that we're spending the majority of it on tasks that are important. Of course we'll want to get to the urgent tasks as soon as possible, but we need to block some time for long-term planning and execution. Spending time on long-term tasks might not bear fruit right away, but it can be critical when dealing with a large incident. For example, setting up your infrastructure so that you can easily roll back changes or deploy new servers when needed takes a large chunk of time. But investing in the future can save you even more time and user frustration when responding to a problem. Researching new technologies is another task in this category. IT is always evolving and it's important to have time set aside to stay up to date. Figure out if it's time to migrate the web server to different software, update the mail server to a new OS version, or deploy voice-over IP throughout your company. Another important task that might not necessarily be urgent is solving technical debt. When you work in IT, you waste time a lot. What does it mean? Technical debt is the pending work that accumulates when we choose a quick-and-easy solution instead of applying a sustainable long-term one. We call that a few times already though in solving the problem we might apply a short-term remediation to fix it right away, and then plan for a long-term solution to prevent it from happening in the future. Until we have fixed the sticks, the workaround we created is technical debt because we need to spend time keeping it in place even if it's not the best solution. Whenever we go for short-term solution and leave the long-term solution for later, we're creating technical debt. This might be the right decision in the moment to get us out of a crisis and let our users get back to work, but we need to unscheduled time to apply the long-term solution that will make our future lives easier. Technical debt can also be generated by external parties. For example, when a new version of the software we're using is released, will need to schedule time to upgrade it. Until we do, that pending upgrade is technical debt. So we've made it clear that we need to focus our work on tasks that are important, but what can we do about interruptions which are urgent but not important? If you work in IT support, you have to be interrupted, it's part of the role. So you'll need to plan to deal with those interruptions effectively. If you work on a team, you can rotate the person dealing with those interruptions. Maybe someone takes care of them in the morning and a different person in the afternoon, or you take turns each day. If you work independently, you can try to establish a set of ours when users can expect to reach you for a normal requests, and the rest of the time only be available for emergencies. The key here is to have a window of time reserved when you're not going to be interrupted. That's the time when you can get the most important tasks done when you can fully concentrate on dealing with complex issues and finding solutions for tricky problems. Depending on your role and how the company works, you might need to get this work done in a different location to avoid people walking up to your desk, or actively silencing any of your notifications to avoid getting interrupted and distracted by unimportant conversations. So assuming that you've managed to set some time aside to work on these important but not urgent tasks, how do you make sure that you work on the right things with the right priorities? That's coming up in our next video.

### Prioritizing Tasks

In our last video, we talked about how we need to make sure that we have the time available to work on tasks that are important, but not necessarily urgent. But sometimes it feels like everything is important, and everything is urgent. Say you need to deploy a new computer for the person that's starting tomorrow. Upgrade the VPN service to the latest version because the old one has a security vulnerability. Fix a permissions problem that's preventing a group of users from accessing the inventory data. Check out a problem with the mail system that's causing some emails to get randomly rejected. And so many other things that by now you've lost track of them. What can you do to figure out how to spend the limited time that you have? There's a lot to say about this, and everyone works a little differently. So you'll need to find the system that works best for you. But let's cover the basic structure that can help us get organized and prioritize our tasks. The first step is to make a list of all of the tasks that need to get done.

You can make this list on a piece of paper, a text file in your computer, a bug tracking system, or a ticket management system. Whatever works for you. The point is to have all the tasks listed in one place to avoid depending on your not always perfect memory later. Once you have the list, you can check the real urgency of the tasks. Ask yourself, if any items don't get done today will something bad happen? If yes, then those should be worked on first. Once you're done with the most critically urgent tasks, you can look at the rest of the list and assess the importance of each issue.
Start transcript at 1 minute 45 seconds

Even when it looks like everything is important, you should be able to tell that some things are more important than others. For example, a task that will benefit more people is more important than a task that will benefit less people. If there are a bunch of different tasks that depend on you completing one, that roadblock is more important to clear than the rest. If it still seems like everything is on fire, you can try dividing the tasks into groups of most important, important, and not so important. And then sort the tasks inside each group, but don't spend too much time doing this sorting. In the end, the exact order isn't what matters. What matters is that you spend most of your time working on the most important tasks. And if you work with a team of people, it's a good idea to share both the list of tasks and the standard of prioritization among team members. This helps you avoid having to do the work multiple times and coming out with different priorities. Once you have a list of the most important tasks to work on, you'll want to have a rough idea of how much effort they'll take.

We'll talk more about estimating times in the next video. This isn't about exact timing, it's about assigning rough sizes. One common technique is to use small, medium, and large. And when the range of sizes is big enough, include extra small or extra large if needed. Once you identify the most important tasks and how big they are, you can start working on them. If possible, try to start with the larger, most important tasks to get those out of the way first. But as we called out, when our work involves IT support, we know that we'll have to deal with interruptions. And working on complex tasks while getting interrupted can be very frustrating. I hear that. One strategy that can help us with that is saving the most complex tasks for the moments when we're less likely to get interrupted. If you know that you get busiest in the morning, and you tend to have more quiet time during the afternoon, it makes sense to work on easy and quick tasks early in the day. Save the most complex tasks for later, when you'll have more time to concentrate on them. But when your focused time starts, you should make sure that you work on those large complex tasks and not on the easy ones. Otherwise, the complex tasks will never get done. The key here is to always work on important tasks. If a task is not important, it shouldn't be done at all. Really, we live by this rule here at Google.

Then select which task you're going to deal with depending on urgency and how much time you can devote to it, starting with the biggest tasks that you can fit in the time you have available. But keep in mind, this shouldn't stop you from taking a break or working on experimental projects. Taking breaks is important because it allows our creative minds to stay fresh, and working on a fun side project can help us research emerging technologies and come up with new ideas. Did you know that this very certificate program got its start as a side project at Google? Okay, but what if the unthinkable happens? What can we do if after all of this prioritizing, sizing, and ordering there's just too much work to be done and too few hours in the day? The first thing to know is this is normal, most people working in IT have too much to do and can't get all the things they want done. Unfortunately, us humans can't multiply ourselves on command yet and working extra hours is not sustainable long-term. Which means there are basically two options, either you get extra help from other team members or you decide that some tasks weren't really that important, and they won't get done. For both of these options, you'll need to involve other people, like your manager, and make sure that expectations get clearly communicated.

Some tasks, like fixing the permissions in a directory, changing a faulty keyboard, or installing a new application on a single computer, can be self-contained and completed in a small amount of time. Other tasks, like upgrading the database software to a new version, automating the creation of user accounts, or writing a wrapper to adapt to incompatible programs, are larger projects that can take several days or maybe even weeks to complete. When that's the case, it's important to have a rough estimate of how long the tasks will take to be completed and to clearly communicate expectations to those affected. We'll cover these two aspects in the next couple of videos.

### Estimating the Time Tasks Will Take

As we've called that before, 

**when deciding whether a manual task needs to be automated, we should consider two things; how many times we'll do the task over a period of time and how long it takes to do it manually.**

**From there, we can figure out if that number is larger than the time it will take us to write the automation.**

This sounds great in theory, but the problem is that we don't know how long it'll take us to write the automation until we've actually written it. All we can do is estimate it, and most of us are really bad at estimating how long tasks will take. 

**We tend to be too optimistic about the amount of time that a certain piece of code will take us to write or a certain infrastructure will take us to set up.**

**Usually, our first instinct is to consider how much we can get done with an ideal amount of focus on the work and a full grasp of the problem we're trying to solve. We forget to take into account the many obstacles that we might face like finding a bug that we don't know how to fix, being interrupted by a problem that needs more urgent attention, or discovering that a new tool doesn't work well with the rest of the tools we have in place.**

**So if you're trying to estimate how long it will take you to complete a project, big or small, you need to be realistic. Avoid being overly optimistic with your time estimates.**

 The best way to do this is to compare the task that you're trying to do with similar tasks that you've done before. This way, you're not estimating based on how long you would like the project to take but on how long other similar projects actually took in the past. If the task at hand is large, it might be hard to find something similar enough to use for comparison. So to make a better estimate of a bigger than average project, you'll want to chop it up. Split the task into smaller steps. Compare each step to a similar task that you've done in the past and assign an estimated amount of time to each step based on that. If one smaller step is still too large, then split it into even smaller pieces until you can compare each piece of the puzzle was something that you've done before. Once you've got all those estimated times, just add them up and you'll have a rough estimate of how long the whole task will take. But even that's going to be optimistic since putting all the pieces together will take additional time. So once you have a rough estimate of the total time of all the steps, you want to factor in some extra time for integration. This should also come from prior experience. Think about how long it took you to integrate the pieces of a project before, and you'll have a rough idea of how much to add to the previous value. Time really flies huh? Knowing how optimistic we humans are, even after basing those estimations on previous experience, the number you come up with is going to be very close to the best possible scenario. Even if you're prepared for something to go wrong, it's impossible to anticipate new unknown bumps in the road, so take this estimation and multiply it by a factor. Once again, this factor works best when it's based on previous experience. So if the last time you did this exercise, it took you three times longer to complete the task than you'd planned, go ahead and multiply your estimation by three. This might seem like we're inflating the numbers, but remember, you want to have a grounded estimate of how long it will take you to complete the task. That means taking into account the obstacles that you'll certainly run into but haven't come across yet. No matter how detailed we are, the final estimation won't ever exactly match the time it takes, but it will give us a rough idea of whether we can complete the task in a few hours, days, weeks, or months. Once you've made your estimation, you want to note it down somewhere so that you can check later to see how close you were to the original number. You can adjust future estimations based on that. You will also want to communicate with those affected and let them know when they can expect the task to be done. We'll talk more about that in our next video.

### Communicating Expectations

When you're dealing with an issue that's affecting one or more users, you might feel rushed to meet expectations, SAP or the people you're helping. Everyone's got their own ideas of how long it will take you to solve the problem and when they can expect a solution. They might be wondering, what's the holdup? If the issue is that the users spilled coffee on their keyboard and needs a new one, the expectation is that replacing the keyboard will be a very small task that will take almost no time. If the issue is that there's a new employee starting soon and they need a new computer setup for them, the expectation is that it will take much longer than replacing a keyboard. Even if we have an automated process for setting up new computers, which means there's very little manual work, to have successful interactions with our users, it's important to understand these implicit expectations and let users know if fixing the problem will take longer than they expect. Users will be happy if the issue is resolved within their expectations, but will become frustrated if it takes much longer than they thought. But as long as we communicate with them early about the circumstances, they will be able to understand this and manage their time accordingly. Say you have to replace a keyboard but you have no spares available. This means, you'll need to buy a new one or maybe even a whole batch to have a spare available next time. It's important to communicate upfront to the user that in this case, the replacements will take more time and then figure out how critical getting the replacement is. If the user is an accountant, working on the salary deposit order, which needs to be sent to the bank in one hour or nobody gets their payment on time, you might opt for giving them your keyboard while you go and buy another one at the closest hardware store. On the flip side, if the user can work on their laptop until the next day when a new batch of keyboards is scheduled to arrive, you don't need to go out of your way to get early replacement. It's also important to let users know if there are any conflicting priorities that might delay the response to whatever they need. Say a user calls you to request access to a shared resource, but you're in the middle of dealing with an issue that's causing the company's database to be offline. Even if the user request is quick and easy to solve, fixing the database is critical and affects the whole company, so it should take priority. In this case, make sure you tell the user that you're dealing with a crisis and that you'll help with their request once the crisis is resolved, give them an idea of when they can expect their issue to be fixed so they can plan what to do next. So as a general rule, communication is key. Try to be clear and upfront about when you expect the issue will be resolved, and if for any reason the issue isn't solved by then, explain why and what the new expectation should be. Unfortunately, when the issue you're trying to solve involves troubleshooting and debugging, it's usually very hard to give an accurate estimate of how long it will take you to fix the problem. Notice a theme, estimating the time it takes to perform more complicated work is tough. A lot of your time will be spent investigating looking into what's going on and figuring out what should be happening. In that case, make sure to let users know when they can expect an update on their issue and give them timely updates, if possible it's a really good idea to have users filed the requests through a ticket tracking system. Using a system like this has a ton of advantages. Having all the work you need to do in one place lets you organize your tasks by priority as we discussed before. Receiving reports of issues through a system instead of a phone or chat, lets you make better use of your time. You can now decide when you'll look at the list of issues instead of getting interrupted in the middle of a task, and when you have an update for an issue that you've been working on, you can easily update the ticket with news without having to track down users to let them know what's up with their request. Finally, try out some practical shortcuts when dealing with users. It makes sense to take some time to think about the work you do and figure out ways to avoid interruptions and save time. For example, if a user tells you that their mouse doesn't work, your first instinct might be to go check it yourself and then bring a new one if necessary, but that's a lot of back and forth, instead you could ask the user to bring the faulty mouse to you so that you can test it at your computer and if it's broken change it with a new one or even better, if you trust your users, you might even leave a set of mice, keyboards, and other accessories available for users to take when the one they're using breaks down. That's what we do here at Google and it saves us a ton of time and frustration. Along the same lines, if your company's budget allows, you could have a couple of spare computers ready to be used. That way, when a computer breaks down, you can get the user back to work as quickly as possible, then you can debug the faulty computer at your own pace. But not every issue can be solved by having spare devices. Sometimes spending time on improving your infrastructure can help you get more done in less time. Automating processes like installing new computers, setting up new user accounts, deploying virtual machines, or rolling back changes to previous versions can help save you a lot of time when you're responding to an incident. Up next is a reading, including links with more information on how to make the best use of your time, followed by a practice quiz to check that all of this made sense. Should be an easy one, considering how fast you're chugging through this module.

### Dealing with Hard Problems

You might be wondering, why is debugging so hard that we need an entire course on it? Brian Kernighan, one of the first contributors to the Unix operating system and co-author of the famous C programming language book, among many other things, once said, everyone knows that debugging is twice as hard as writing a program in the first place. So if you're as clever as you can be when you write it, how will you ever debug it? This is a warning against writing complicated programs. If the code is clear and simple, it will be much easier to debug than if it's clever but obscure. The same applies to IT systems. If the system is engineered very cleverly, it will be extremely hard to understand what's going on with it when something fails. It's important to focus on building systems and applications that are simple and easy to understand. So that when something goes wrong, we can figure out how to fix them quickly. So how do we do this? One piece of advice I found really valuable is to develop code in small, digestible chunks. Every so often, I stop and test what I've written. The hardest thing to do is to try to debug something if I'm running it for the first time only after I've completed it. There are so many places things could have gone wrong. Another lesson that's super useful is to keep your goal clear. If you're writing code, try writing the tests for the program before the actual code to help you keep focus on your goal. If you're building a system or deploying an application, having documentation that states what the end goal should be, and the steps you took to get there can be really helpful. To both keep you on track, and figure out any problems that might turn up along the way. We called out at the beginning of this course that solving technical problems is a bit of an art, and that it can be fun when things finally click together. On the flip side, the worst part of troubleshooting and debugging is when we get stuck. When we can't think of any other reasons why the program is failing, or we can't figure out what else we can do to fix it. In this course, we've given you a bunch of tools and processes to follow that can hopefully help you avoid getting stuck on a lot of these situations, but we can't cover absolutely everything. You might still find yourself facing an issue that you have no idea what to do about, and that's okay. If you're in a sticky situation, the main thing to do is to remain calm. We need our creative skills to solve problems, and the worst enemy of creativity is anxiety. So if you feel that you're out of ideas, it's better to take your mind off the problem for a while. Maybe grab a cup of coffee, or take a walk outside. Sometimes a change of scenery is all we need for a new idea to pop up and help us figure out what we're missing, true in coding and in life. If the problem you're trying to solve is complex and affects a lot of people, it can get really stressful to try to fully debug it with everyone waiting on you. That's why it's better to focus first on the short-term solution, and then look for the long-term remediation once those affected are able to get back to work. And don't be afraid to ask for help. Sometimes just the act of explaining the problem to someone else can help us realize what we're missing. There's a technique called rubber duck debugging, which is simply explaining the problem to a rubber duck. It sounds whimsical, and you may look like a quack, but it can really work. Because when we force ourselves to explain a problem, we already start thinking about the issue differently. And remember that no one knows absolutely everything. Sometimes the best way to learn new skills and techniques is to ask others for help. We're all in this thing together. There are times when I know that if I spend enough hours on a problem, I'll probably figure out a solution, but is that the best use of my time? Usually, the better answer is to ask someone who has done it before, to save time and frustration. And then use the problem at hand as an opportunity to keep learning, so that the next time, I can do it on my own. When you ask a colleague for their help with debugging a problem, be careful not to tell them what you think the root cause of the issue might be. Instead, tell them about the symptoms, and see what questions they ask and what possibilities they probe. They might come up with completely different paths to explore. Of course, our lives as IT specialists would be much easier if we could avoid problems altogether. Up next, we'll look into some proactive approaches to catching issues before they affect any users.

### Proactive Practices

Something that IT specialists and exterminators have in common is dealing with bugs. I just love a good coding joke. Anyhow, moving on, it can be bugs in our software or someone else's software. But we'll come across lots of bugs that trigger lots of different failures in our programs. There's a bunch of strategies we can adopt to make our lives easier, by catching issues before they affect our users or making troubleshooting simpler by having better information. We've touched upon some of them here and there but now, it's time to deep dive. 

**To avoid having to scramble to fix things when there's an outage, it's really helpful to have infrastructure that lets us test changes in advance so that we can check that things are working as expected before they reach our users.** 

If we're the ones writing the code, one thing we can do is to make sure that our code has good unit tests and integration tests. If our tests have good coverage of the code, we can rely on them to catch a wide array of bugs whenever there's a change that may break things. For these tests to be really meaningful, we need to run them often, and make sure we know as soon as they fail. Setting up continuous integration can help with that. Another step in this direction is to have a test environment, where we can deploy new code before shipping it to the rest of our users. This serves two purposes. First, we can do a thorough check of the software as it will be seen by the users. Depending on the software and how often we update it, we can do both automated and manual tests in this environment. Second, we can use this test environment to troubleshoot problems whenever they happen. We can try possible solutions and new features without affecting the production environment. Taking this even further, another recommended practice when managing a fleet of computers is to deploy software in phases or canaries. What this means is that instead of upgrading all computers at the same time and possibly breaking all of them at the same time, you upgrade some computers first and check how they behave. If everything goes fine, you can upgrade a few more, and so on until you're confident enough to upgrade the remaining part of the fleet. As the saying goes, like a canary in a coal mine. To make the best use of this practice, we'll need to be able to easily roll back to the previous version. Depending on the software, this might require more or less infrastructure. But trust me, it's worth spending the time setting up that additional infrastructure. If you deploy to software version that was broken and suddenly a bunch of your computers aren't working correctly, you'll want to roll them back to a previous state as fast as possible. Now, even with all these preventative measures, bugs will still filter through and problems will occur. We can make our troubleshooting easier by including good debug logging in the code. That way, whenever we have to figure out an issue, we can look at the logs and get a pretty good idea of what's going on. Another method that can help us is having centralized logs collection. This means there's a special server that gathers all the logs from all the servers or even all the computers in the network. That way, when we have to look at those logs, we don't need to connect to each machine individually, we can comb through all the logs together in a centralized server. Similarly, having a good monitoring system can be super helpful. We can use it to catch issues early before they affect too many users. During a debugging session, we can look at the collected data to try to determine if there's anything out of the ordinary going on. We called out ticketing systems a few times already, because we can't stress their importance enough. Making good use of them can help us save a lot of time when trying to get to the bottom of a problem. If we ask users to provide the needed information up front, we don't have to waste time and go back and forth. Even here, we can look at opportunities for automation. Say you almost always want some specific info from the users computers, you can automate getting it by creating a script that gathers all the data you want and have the users attach it to the ticket. Finally, remember to spend time writing documentation. Just as importantly, store the documentation in a well-known location. Even if writing documentation isn't especially fun, having good instructions on how to solve a specific problem, knowing how to diagnose what's going on with the server, or tracking the known issues in a system can be real time savers. At Google, we have a bunch of docs called Playbooks where we detail what a person who's on call can do to diagnose and mitigate a ton of different problems. By keeping this information updated, we make sure that no matter who the person on call is, everybody has access to the knowledge base accumulated by the whole team. It doesn't stop there. If we're dealing with systems that change and grow, we can proactively plan for the additional capacity that we'll need in the future. Speaking of planning ahead, you can plan to hear more about this in our next video.

### Planning Future Resource Usage

We discussed in earlier videos what we can do when our programs are misusing resources like memory, disk, network, or CPU. But sometimes, it's not a question of misusing resources, but rather missing resources. A database server is expected to use more disk storage as more data gets stored. Or a web server is expected to use more network bandwidth as the service grows in popularity. If you're dealing with a service that's expected to grow and will acquire more resources in the future, it makes sense to spend some time thinking about what that might look like. 

**Planning ahead will prepare you for when you need additional resources, instead of having to scramble for them at the last minute.**

Lets say the database growth is expected to be one megabyte per day, and you have 500 megabytes of free-space. You can use that storage for almost two years. But if the growth is expected to be 10 megabytes per day and you only have those 500 megabytes available, then you need to start figuring out a plan that will allow your database to keep growing at that pace. Otherwise, you run out of space in a couple of months. Once you've figured out the current usage and the expected growth, don't forget to write this down so you can refer to it in the future and check if anything has changed. 

**If you find that you'll soon be running out of space, what you'll do next will depend on what the system does, and the importance of the data.**

 You might decide that you don't really want to store all that data, and instead clean up anything that's not really necessary, or you might decide that you really need to have a lot more storage available. In that case, you might opt for buying a network attached storage or NAS that can be attached to your server for additional disk space. Migrating to a different type of storage takes time, and can be tricky to do right under pressure. So it's important to do this kind of planning in advance and not wait until the disk is completely full. This means monitoring the usage growth of the computer to see if there are any trends that need attention. If the service using the database suddenly becomes very popular, the daily growth can increase so much that we'll need to find a better solution sooner than we thought. Our monitoring system should trigger an automatic alert when that's the case. An interesting strategy for making the best possible use of resources, is to mix and match the processes that run on the computers, so they make use of all the available resources. If you have a process that's CPU intensive and takes almost all the available CPU on a computer, you can still run processes that are IO intensive, reading and writing a lot of data to the hard drive. Or if you have a service that requires a lot of RAM, you can pair it with another one that uses very little memory, and mostly sends and receives data over the network. An alternative for having to deal with all these resources like figuring out when to buy more and how to distribute them, is to migrate those systems to the Cloud. Setting up your service to run on the cloud will require some initial setup time, as well as an ongoing cost for the Cloud resources you're using. But while this is more expensive than what you'd pay when running the service on premise, you're basically delegating all your capacity planning needs to your Cloud provider. That way, if the initial setup doesn't have enough space, you can simply attach a bigger hard drive. Or if the program needs more RAM, you can just deploy the service in a virtual machine with more memory assigned. If you decide that moving to the Cloud is a good way to go for your company, remember that you'll also need to plan for that. Migrating your services to run fully or even partially in the Cloud, requires work on your side. So you'll need to decide if and when to make the leap, to avoid your service having an outage because it ran out of resources. Still with us, you're doing great. We're coming towards the end of the module, and I hope you are as proud as we are of the progress you've made. Your thinking ahead and learning some seriously important skills that will serve you well up there in the word, which brings us to our last topic; making sure that problems are properly addressed in a long-term.

### Preventing Future Problems

Throughout our course, we've called out several times that, whenever we're faced with an issue, it's usually best to find a quick workaround. So that those affected can get back to work as soon as possible. Say your database server crashed because it ran out of space. You can solve it quickly by adding an extra hard drive and starting the service back up. But remember, our work doesn't finish there. Once the affected users are happily doing their job, we need to look for a long-term solution that will prevent the problem from happening again in the future. In the database server scenario, that would be detecting that the disk is running out of space before it happens. So how do we do that without a crystal ball? One key strategy is to make good use of monitoring. There's a lot to say about monitoring, so much that we could have a whole course on this subject. The short version of it is that you want the computers you care about to send their data to a centralized location that aggregates all this information. And then you want to be able to look at both the information yourself, and trigger alerts when the values are not within acceptable range. When you first set up a monitoring system, you might not be sure what information to prioritize, so start with the basics, CPU, disk, memory, and network usage. As time passes and you have to deal with more incidents, you'll probably discover other metrics that you'd like to include in your monitoring system. For example, if you have to debug a problem related to a computer overheating, you'll want to include the temperature sensor's data in your monitoring system. You'll also want to include information related to the specific service running on the computer. If it's a web server, you'll want to know the ratio between successful web responses and errors. If it's a database server, you'll want to know how many queries that are being served over time. And whenever you have to deal with an incident that wasn't caught by the monitoring system, remember to set up new monitoring and alerting rules that will notify you about the problem if it ever happens again. An important capability of monitoring is to include the measurements taken along a period of time. That way, we can keep track of how we're using our resources, and catch changes in tendencies early on to help us with planning. Having good monitoring will let us know early on if things are broken. But how do we make sure that the things we fix stay fixed? We've mentioned this already, but it's worth repeating. If you have to work around an issue in an application developed by someone else, it's important that you report a bug to the relevant developers. That way, those in charge of the code can take your case into account and make it work correctly in the future. If you don't do this, it's possible that the workaround you figured out for the current version is not sufficient for the next version, and you'll have to figure out a whole new workaround. When reporting a bug to someone else, remember all the best practices that we talked about earlier. Let them know what you were trying to achieve, what you did, what the expected result was, and what the actual result was. Include your reproduction case and workarounds for the issue. If you have access to the source code of the project, providing a patch that fixes the issue increases the chance of that code getting fixed. On the flip side, if you have to work around an issue in the software that you own, make sure that you write a test that catches the problem.

That way, you can be sure that you won't ever make a change to the code that will trigger that same issue again. And even if you're not in charge of the development of the software, you can still run automatic tests whenever there's a new version, just to check if it still works as expected. So make sure you perform these tests whenever a new version of the application comes around. Finally, regardless of whether the bug came from software that you wrote or someone else wrote, make sure that you document the key pieces of what you did, how you diagnosed the issue, and how you squashed it. That way, if the issue happens again, you or whoever else needs to deal with it will be able to quickly apply the solution, instead of spending valuable time investigating. Coming up, a quick quiz to make sure that all these concepts have made sense.